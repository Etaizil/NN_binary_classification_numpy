# Neural Network with NumPy

## Description

This repository contains a neural network implementation from scratch using only **NumPy** for a **binary classification** task. The network trains to classify two chosen **sign language hand digits**, focusing on a simple binary classification problem.

The motivation behind this project was to **deepen my understanding of implementing a neural network** and learn the fundamentals, such as **feedforward** and **backpropagation**. By building the network from the ground up, I explore the core mechanics of neural networks, focusing on how they work at a fundamental level.


## Key Features

- **Custom Neural Network Implementation**: Built using only **NumPy**, providing insight into the fundamental workings of neural networks and a deeper understanding of machine learning principles.
- **Binary Classification**: The network will train to classify sign language hand digits into two chosen categories.
- **CUDA Support**: The code can leverage GPU acceleration for faster computations. In **Google Colab**, go to **Runtime** â†’ **Change runtime type** â†’ **Select "T4 GPU"** â†’ **Save**.
- **Training & Evaluation**: Includes Jupyter Notebook for training the network, evaluating its performance, and plotting loss and accuracy metrics.

## Dataset

The dataset used in this project is based on **sign language hand digits**.

## Getting Started

### Run the Notebook on Google Colab
To get started, simply run the notebook on **Google Colab**. The workflow is easy and straightforward, with no setup required â€” the dataset is handled automatically.

ðŸ“Œ **Access the notebook here:** [Google Colab Notebook](https://colab.research.google.com/drive/1GiElgg9bb9IzAfOTMoBGt8pI8bmW-azh?usp=sharing)  

---

## Results

The network trains on the **sign language hand digits** dataset and evaluates its classification performance. **Loss and accuracy** are plotted throughout both the training and testing processes. Each run starts training from scratch, as the model is not saved after training.

For further details on the model design and results, please refer to the attached report, which provides a comprehensive analysis of the entire project.

---

Feel free to reach out if further clarification is needed!


## License

This project is licensed under the MIT License - see the LICENSE file for details.
